%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  
%  Author: Andre Minoche, a.minoche@garvan.org.au
%  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{article}
 
  \usepackage[
   top    = 2.00cm,
   bottom = 2.00cm,
   left   = 2.00cm,
   right  = 1.50cm]{geometry}


 \renewcommand{\familydefault}{\sfdefault}
 

\usepackage{caption} 
\usepackage{textcomp}
 
\linespread{1.2} 
 \setlength{\parindent}{0pt}

\usepackage{float} 
\usepackage{color}
\definecolor{green}{RGB}{38,179,0}
\definecolor{orange}{RGB}{255,120,0}

\usepackage{underscore}

\makeatletter
\let\old@float\@float
\def\@float{\let\centering\relax\old@float}
\makeatother

 \begin{document}
  
   <<echo = FALSE, message = FALSE>>=
 	cSample = as.character(Sys.getenv("PARAM_SAMPLE", names = TRUE));
	projectPath = as.character(Sys.getenv("PARAM_PROJECT_PATH", names = TRUE));
	cSampleC = as.character(Sys.getenv("PARAM_CONTROL_SAMPLE", names = TRUE));
	validTF = as.character(Sys.getenv("PARAM_EVAL", names = TRUE));
	
	contrStatsPathC = as.character(Sys.getenv("PARAM_ControlStats_PATH", names = TRUE));
	
	varFile=paste(sep="",projectPath,"/SVs/qc/",cSample,".stat.tab")
	varTab=read.table(varFile, header=TRUE, row.names=1, sep="\t", stringsAsFactors=FALSE)
	samplesA=colnames(varTab)
	
	varFileC=paste(sep="",contrStatsPathC,"/sample.stat.tab")
	varTabC=read.table(varFileC, header=F, row.names=1, sep="\t", stringsAsFactors=FALSE)
	
		
	varTabD=data.frame("timesStDev"=as.numeric(),"desc"=as.numeric())
	#str(varTabD)
	varTabD["PcNotPropPair",]=c(2,"Percent reads pairs not mapping as proper pair")
	varTabD["PcMapDiffChr",]=c(2,"Percent reads pairs mapping on different chromosomes")
	varTabD["covtimesStDev",]=c(2,"timesStDev of read coverage")
	varTabD["svStatHigh",]=c(4,"High confidence variant")
	varTabD["svStatPassHigh",]=c(2,"Pass and High confidence variants")
	varTabD["svStatLow",]=c(2,"Low confidence variants")
	varTabD["svStatCNVs",]=c(2,"CNVs")
	varTabD["svStatCNVLoss",]=c(2,"Loss")
	varTabD["svStatCNVGain",]=c(2,"Gains")
	varTabD["svStatNonCNV",]=c(2,"Balanced events including inversions and translocations")
	varTabD["svStatToolLumpy",]=c(4,"Lumpy calls")
	varTabD["svStatToolCNVnator",]=c(4,"CNVnator calls")
	varTabD["svStatToolBoth",]=c(4,"In both")
	varTabD["svStatGene",]=c(2,"Affecting genes")
	varTabD["svStatRare",]=c(2,"Rare")
	varTabD["covStdev",]=c(2,"Stdev of coverage")
	varTabD["concInsSizeMin",]=c(2,"Concordant size min (green)")
	varTabD["concInsSizeMax",]=c(2,"Concordant size max (green)")
	varTabD["insMean",]=c(2,"Mean mapping distance size (blue)")
	varTabD["insSD",]=c(2,"Stdev mapping distance size")
	varTabD["inputDiscPairs",]=c(2,"Input discordant pairs")
	varTabD["inputSplitReads",]=c(2,"Input split reads")
	varTabD["svStatRarePassHigh",]=c(4,"Rare Pass and High confidence")
	varTabD["svStatRarePassHighGene",]=c(4,"Rare Pass, High confidence, affecting genes")
	varTabD["svStatRarePassHighGeneCNV",]=c(4,"Rare Pass, High confidence CNV, affecting genes")
	varTabD[,1]=as.numeric(varTabD[,1])
	
	printVal <- function(varN){ # varN="svStatRarePassHighGeneCNV"	
		cStDev=as.numeric(varTabC[varN,"V2"]);if(cStDev>10){cStDev=round(cStDev,0)}else{cStDev=signif(cStDev,2)}
		cAvg=as.numeric(varTabC[varN,"V3"])	;if(cAvg>10){cAvg=round(cAvg,0)}else{cAvg=signif(cAvg,2)}
		cNum=as.numeric(varTab[varN,1]);if(cNum>10){cNum=round(cNum,0)}else{cNum=signif(cNum,2)}
		
		cTimesStdev=(cNum-cAvg)/cStDev;if(abs(cTimesStdev)>10){ cTimesStdev=round(cTimesStdev,0)}else{cTimesStdev=signif(cTimesStdev,2)}
		
		
		if(  abs(cTimesStdev) < varTabD[varN,"timesStDev"] ){  resultMsg="\\textcolor{green}{OK}"   }else{  resultMsg="\\textcolor{orange}{!!!}" }	
		if(varTabD[varN,"timesStDev"]==4){ zCutOff="\\textsuperscript{b}" }else{ zCutOff="" }
		
		cat(paste(varTabD[varN,"desc"],": ",cNum," [$\\mathit{\\mu}$ ",round(cAvg,1),", $\\mathit{\\sigma}$ ",round(cStDev,1),", $\\mathit{z}$ ",round(cTimesStdev,1),"] ",resultMsg,zCutOff," \\\\\n",sep=""))			
	}

	printTable <- function(tmp1X,cCapt){ # varN="PcNotPropPair"
			
		cat("\\begin{table}[ht]","\n")
		cat("\\caption{",cCapt,"}","\n")
		cat("\\captionsetup[table]{skip=10pt}","\n")

		cat("\\centering","\n")
		cat("\\begin{tabular}[ht]{",paste(sep="","l|",paste(rep("r",ncol(tmp1X)),collapse="|")),"}","\n")
	
		cat("\\hline\n","Size"," & ",paste(sep="",paste(colnames(tmp1X),collapse=" & "),"\\\\"),"\n")	
		for(k in 1:nrow(tmp1X)){ cat("\\hline\n",rownames(tmp1X[k,])," & ",paste(sep="",paste(tmp1X[k,],collapse=" & "),"\\\\"),"\n")		}
			
		cat("\\hline","\n")
		cat("\\end{tabular}","\n")
		cat("\\end{table}","\n")
	}
		
	@
	
	
\title{SV evaluation report sample \Sexpr{cSample}}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  QC from bam alignment file



<<echo = FALSE, message = FALSE, results='asis', fig.width=4, fig.height=3.5, out.width='.39\\linewidth', fig=TRUE>>=	
	
	
	cat(paste("\\centerline{$\\mathit{\\mu}$  mean in control, $\\mathit{\\sigma}$  stdev in control, $\\mathit{z}$  z-score. ",sep=""))
	cat(paste("\\textcolor{green}{OK} if $\\mathit{|z|}$ $\\leq$ 2, else \\textcolor{orange}{!!!} }",sep=""))
	
	cat(paste("\\section{QC from bam alignment file}\n",sep=""))
	
	cat(paste("Input bam file: ",basename(varTab["bamfile",1])," \\\\\n",sep=""))
	for(cCat in c("PcNotPropPair","PcMapDiffChr","covStdev")){
		printVal(cCat)
	}
	
@



\vspace{8pt}
\textbf{Mapping distance distribution:}


   <<echo = FALSE, message = FALSE, results='asis', fig.width=4, fig.height=2.5, out.width='.39\\linewidth', fig=TRUE>>=
 	 
	 ################################################  plot the insert size
	#cat(paste("The mapping distance is the genomic distance between two reads of a read pair, reflecting the sequenced DNA fragment size.\\\\\n",sep=""))
	filename=paste(projectPath,"/SVs/qc/insertSizes/",cSample,".txt",sep="")
	tmp1=read.table(filename, header=FALSE, sep="\t", stringsAsFactors=FALSE)
	

	tmp=tmp1[tmp1<1500,]
	rangeV=range(tmp)
	par(mar = c(4, 4, 2, 2), cex.lab = 0.95, cex.axis = 0.9, mgp = c(2, 0.7, 0), tcl = -0.3)
	
	cSD=sd(tmp)
	cMean=mean(tmp)
	varTab["insMean",1]=round(cMean,0)
	varTab["insSD",1]=round(cSD,0)
	
	concRegMin=varTab["concInsSizeMin",1]
	concRegMax=varTab["concInsSizeMax",1]
	
	hist(tmp, breaks=seq((rangeV[1]-10),(rangeV[2]+30), by=20), #cex=0.5,cex.axis=0.5,cex.main=0.5,cex.lab=0.5,
	cex.sub=0.8, xlim=c(0,1500),
	main="",
	ylab="Count", xlab="Mapping distance")
	abline(v=mean(tmp), col="dodgerblue3", lwd=3)
	abline(v=concRegMin, col="limegreen", lwd=2)
	abline(v=concRegMax, col="limegreen", lwd=2)

	cat(paste("\\vspace{8pt} \\\\\n",sep=""))
	for(cCat in c("concInsSizeMin","concInsSizeMax","insMean","insSD")){
		printVal(cCat)
	}

	 	
	################################################ Input discordant pairs and split reads
	cat(paste("\\section{Input discordant pairs and split reads}\n",sep=""))

	for(cCat in c("inputDiscPairs","inputSplitReads")){
		printVal(cCat)
	}
			 
 		
	################################################ Coverage by chromosome
	 
	cat(paste("\\clearpage\n",sep=""))  
  	cat(paste("\\section{Coverage by chromosome}\n",sep=""))
	 
	 cat(paste(sep="","Average sequence coverage: autosomes ",round(as.numeric(varTab["avgCovAutosomes",1]),1),
	 "x, X ",round(as.numeric(varTab["avgCovX",1]),1),"x, Y ",
	 round(as.numeric(varTab["avgCovY",1]),1),"x \\\\\n"))
	 	 
	 numX=round(as.numeric(varTab["avgCovX",1])/as.numeric(varTab["avgCovAutosomes",1]),1)*2
	 numY=round(as.numeric(varTab["avgCovY",1])/as.numeric(varTab["avgCovAutosomes",1]),1)*2
	 
	 
	 cStrXY=paste(sep="",paste(sep="",collapse="",rep("X",numX)),paste(sep="",collapse="",rep("Y",numY)))
	 
	 if(cStrXY != "XX" & cStrXY != "XY"){ cat(paste(sep="","Inferred gender: ","\\textcolor{orange}{",cStrXY," !!!}"," (XX female, XY male, XXY Klinefelter\\textquotesingle s Syndrome) \\\\\n")) 
	 }else{ cat(paste(sep="","Inferred gender: ",cStrXY," (XX female, XY male, XXY Klinefelter\\textquotesingle s Syndrome) \\\\\n")) }
	
	 cat(paste("\\\\\n",sep=""))
	
	 cat(paste(sep="","The coverage is normalised by the autosomal average. If the coverage of Y is close to 0, Y0 is plotted representing the background noise. This enables to detect a partial presence of Y. \\\\\n"))
	 
	#cat(paste("\\vspace{8pt} \\\\\n",sep=""))
	 
	avgCov=round(as.numeric(varTab["avgCovAutosomes",1]),1)
	
	@
	
\begin{figure}[ht]

   <<echo = FALSE, message = FALSE, results='asis', fig.width=4, fig.height=3.5, fig.pos = 'H', out.width='.94\\linewidth', fig=TRUE>>=
	
	layout(matrix(1:24, 24, 1))
	par(mar = c(0.1,0.5,0,1), cex.lab = 0.8, cex.axis = 0.9, cex=0.2, pch=20, lwd=2, mgp = c(2, 0.7, 0), tcl = -0.3)
		
	filename=paste(projectPath,"/SVs/qc/chromView/",cSample,".txt",sep="")
	tmp1=readLines(filename)
	tmpS = new.env(hash=TRUE, parent=emptyenv(), size=100L)	
	for(j in 1:length(tmp1)){ tx=strsplit(tmp1[j],"\t")[[1]]; cChr=tx[1]; assign(cChr, tmp1[j], tmpS) }	
	
	filenameC=paste(contrStatsPathC,"/chromView.stat.avg.tab",sep="")
	tmp1=readLines(filenameC)
	tmpCA = new.env(hash=TRUE, parent=emptyenv(), size=100L)	
	for(j in 1:length(tmp1)){ tx=strsplit(tmp1[j],"\t")[[1]]; cChr=tx[1]; assign(cChr, tmp1[j], tmpCA) }
	
	filenameC=paste(contrStatsPathC,"/chromView.stat.sd.tab",sep="")
	tmp1=readLines(filenameC)
	tmpCS = new.env(hash=TRUE, parent=emptyenv(), size=100L)	
	for(j in 1:length(tmp1)){ tx=strsplit(tmp1[j],"\t")[[1]]; cChr=tx[1]; assign(cChr, tmp1[j], tmpCS) }
		
	
	allChr=ls(tmpS);
	nonAutos=allChr[grep("^(chr)*[0-9]+$",ls(tmpS),invert = T)]
	autosom_chr=sort(allChr[grep("^(chr)*[0-9]+$",ls(tmpS),invert = F)])
	
	if (substr(autosom_chr[1],1,3)=="chr"){ 
		autosom_chr=paste(sep="","chr",1:22) 
	}else{ 
		autosom_chr=1:22 
	}
		
	for(cChr in as.character(c(autosom_chr,nonAutos))){ #cChr=as.character(10)
		if (cChr=="MT"){next;}
		if (cChr=="chrM"){next;}
		cChr2=cChr;
		if(cChr=="chrX" & nchar(cChr)>2){cChr2="chrXX"}
		if(cChr=="X" & nchar(cChr)>2){cChr2="XX"}
		
		if(cChr=="chrY" & nchar(cChr)>1){cChr2="chrY"}
		if(cChr=="Y" & nchar(cChr)>1){cChr2="Y"}
		
		tmp2=strsplit(get(cChr,tmpS),"\t")[[1]]; tmp2=as.numeric(tmp2[2:length(tmp2)]);
		NRegs=which(tmp2<0); NoNRegs=which(tmp2>=0); tmp2[NRegs]=NA;

		tmp2CA=strsplit(get(cChr2,tmpCA),"\t")[[1]]; tmp2CA=as.numeric(tmp2CA[2:length(tmp2CA)]);
		tmp2CS=strsplit(get(cChr2,tmpCS),"\t")[[1]]; tmp2CS=as.numeric(tmp2CS[2:length(tmp2CS)]);
		
		tmp2CS[tmp2CS<0.02]=0.02		
		gains=NoNRegs[which(round((tmp2[NoNRegs]-tmp2CA[NoNRegs])/tmp2CS[NoNRegs],1) >= 5) ]
		loss=NoNRegs[which((tmp2[NoNRegs]-tmp2CA[NoNRegs])/tmp2CS[NoNRegs]  <= -5)]
		
		#print(tmp2CA)
		plot(1:length(tmp2CA),tmp2CA-1, xlim=c(0,251),ylim=c(-1,1), xlab="",ylab="", main="", pch=20, type="n",xaxt='n',yaxt='n',bty='n')
		segments(0,0,250,0,col="lightgrey",lwd=0.5)
		abline(v=1:25*10,col="lightgrey",lwd=0.5)
		abline(v=0:5*50,col="black",lwd=0.5)
		
		if(substr(cChr2,1,3)=='chr'){cChr2=substr(cChr2,4, nchar(cChr2)  )}
		mtext(cChr2,side=2,cex=0.5,at=(0),adj=0.2,las=1)
		points(NRegs,rep(0,length(NRegs)),col="sandybrown",type="h")
		
		points(NoNRegs,tmp2CS[NoNRegs]*2,type="h",col="lightgrey");points(NoNRegs,tmp2CS[NoNRegs]*(-2),type="h",col="lightgrey")
		
		points(NoNRegs,tmp2[NoNRegs]-1,cex=0.1,lwd=1,type="h",col="black");
		points(gains,tmp2[gains]-1,type="h",col="blue")
		points(loss,tmp2[loss]-1,type="h",col="red")
	}
 
	legend("bottomright", c("control","sample","loss","gain","N region"),  horiz=T, cex=2, box.col="white", bg="white", border=F, fill=c("lightgrey","black","red","blue","sandybrown"))
	
	cat(paste("\\end{figure}\n",sep=""))  
		

@	 
\clearpage


<<echo = FALSE, message = FALSE, results='asis', fig.width=4, fig.height=3.5, out.width='.69\\linewidth', fig=TRUE>>=
 	 
	################################################ Number called SVs
	 
	 cat(paste("\\section{Number called SVs}\n",sep=""))
	 
		
	cat(paste("\\textbf{By call confidence:} \\\\\n",sep=""))		
	for(cCat in c("svStatHigh","svStatPassHigh","svStatLow")){
		printVal(cCat)
	}
	
	cat(paste("\\vspace{8pt} \\\\\n",sep=""))
	cat(paste("\\textbf{By SV type \\textsuperscript{a}:} \\\\\n",sep=""))		
	for(cCat in c("svStatCNVs","svStatCNVLoss","svStatCNVGain","svStatNonCNV")){
		printVal(cCat)
	}

	cat(paste("\\vspace{8pt} \\\\\n",sep=""))
	cat(paste("\\textbf{By caller \\textsuperscript{a}:} \\\\\n",sep=""))		
	for(cCat in c("svStatToolLumpy","svStatToolCNVnator","svStatToolBoth")){
		printVal(cCat)
	}

	cat(paste("\\vspace{8pt} \\\\\n",sep=""))
	cat(paste("\\textbf{Gene affecting / rare \\textsuperscript{a}:} \\\\\n",sep=""))		
	for(cCat in c("svStatGene","svStatRarePassHigh","svStatRarePassHighGene","svStatRarePassHighGeneCNV")){
		printVal(cCat)
	}

  
	cat(paste("\\vspace{8pt} \\\\\n",sep=""))
	cat(paste("\\textsuperscript{a} Without low confidence variants \\\\\n",sep=""))
	cat(paste("\\textsuperscript{b} \\textcolor{green}{OK} if $\\mathit{|z|}$ $\\leq$ 4 \\\\\n",sep=""))
	
	################################################ 
	################################################ Validation report comparison to NA12878
	################################################ 
	
	if(validTF == 1){
	cat(paste("\\clearpage\n",sep="")) 
	cat(paste("\\section{Sensitivity}\n",sep=""))
  	cat(paste("Compared to NA12878 NIST gold standard consisting of 2664 deletions.\\\\\n",sep=""))
	cat(paste("\\textcolor{green}{OK} if $\\mathit{z}$ $\\leq$ -2 \\\\\n",sep=""))
	
	
	concFile=paste(sep="",projectPath,"/SVs/qc/sensitivity/",cSample,"/resulTable.tab")
	tGold=read.table(concFile, header=T, sep="\t", skip=2, stringsAsFactors=FALSE)

	concFileC=paste(sep="",contrStatsPathC,"/gold_avg_r.tab")
	tGoldCAvg=read.table(concFileC, header=T, sep="\t", stringsAsFactors=FALSE)
	concFileC=paste(sep="",contrStatsPathC,"/gold_sd_r.tab")
	tGoldCSd=read.table(concFileC, header=T, sep="\t", stringsAsFactors=FALSE)


	tGoldX=tGold[c(1:7,11),2:3]
	rownames(tGoldX)=tGold[c(1:7,11),1]
	tGoldX[,2]=paste(tGold[,"concA"][c(1:7,11)]," (",signif(tGold[,"concA"]/tGold[,"countA"]*100,3)[c(1:7,11)]," \\%)",sep="")

	t2GoldXAvg=round(tGoldCAvg[,"concA"][c(1:7,11)],1)
	t2GoldXSd=round(tGoldCSd[,"concA"][c(1:7,11)],1)
	t3GoldX=signif((tGold[,"concA"][c(1:7,11)]-t2GoldXAvg)/t2GoldXSd,2)
	
	t3GoldX[t2GoldXAvg==tGold[,"concA"][c(1:7,11)] & t2GoldXSd==0]=0 # if SD=0 but same number of concordant variant -> z score =0, to obtain a green OK
			
	for(k in 1:nrow(tGoldX)){ 
	if(t3GoldX[k]<(-2) || is.na(t3GoldX[k]) ){  tGoldX[k,3]=paste(sep="","$\\mathit{\\mu}$ ",t2GoldXAvg[k],", $\\mathit{\\sigma}$ ",t2GoldXSd[k],", $\\mathit{z}$ ",t3GoldX[k]," \\textcolor{orange}{!!!}")   }
	else{  tGoldX[k,3]=paste(sep="","$\\mathit{\\mu}$ ",t2GoldXAvg[k],", $\\mathit{\\sigma}$ ",t2GoldXSd[k],", $\\mathit{z}$ ",t3GoldX[k]," \\textcolor{green}{OK}") }
	}

	colnames(tGoldX)=c("Gold standard calls","Concordant calls","Expected")
	printTable(tGoldX,"Concordance to 2664 DEL calls from GIAB NA12878")
	

	par(new=F, mar = c(5,4,2,4), cex.lab = 0.8, cex.axis = 0.9, pch=20, lwd=1, mgp = c(2, 0.7, 0), tcl = -0.3)

	cat(paste("\\begin{figure}[ht]\n",sep=""))  
	plot(1:7,signif(tGold[,"concA"]/tGold[,"countA"]*100,3)[1:7], ylim=c(0,100), xlab="", ylab="% concordant calls",  xaxt="n",  type="b", main="", pch=4 )
	axis(1, at=1:7, labels=paste(tGold[1:7,"fragmentSize"],sep=""),  las=2)
	abline(v=1:7,col="lightgrey")
	abline(h=c(80,90,100),col="lightgrey")
	points(1:7,signif(tGold[,"concA"]/tGold[,"countA"]*100,3)[1:7], type="b",  pch=4 )
	par(new=TRUE)
	plot(1:7,tGold[1:7,"concA"], type="b", log="y", pch=2,  lty=2, col="grey",  axes=F, bty="n", xlab="", ylab="")
	axis(4) # plot axis of y2
	mtext("Number of calls (grey)", 4, 3, cex=0.8) # plot label of y2
	cat(paste("\\end{figure}\n",sep=""))  
	
	
		
  	
 	cat(paste("\\clearpage\n",sep=""))  
  	cat(paste("\\section{Comparison to NA12878 sample}\n",sep=""))  
  	cat(paste("Concordant calls between NA12878 control sample FR05812662 and current sample ",cSample,".\\\\\n",sep=""))
  	cat(paste("Expected values are derived from a set of 8 additional NA12878 control samples. ",sep=""))
  	cat(paste("\\textcolor{green}{OK} if $\\mathit{z}$ $\\leq$ -2 \\\\\n",sep=""))	
  
  	printTable2 <- function(tmp1X,cCapt){ # varN="PcNotPropPair"
			
		cat("\\centering","\n")
		#cat("\\caption{",cCapt,"}","\n")
		cat("\\begin{tabular}[ht]{",paste(sep="","l|",paste(rep("r",ncol(tmp1X)),collapse="|")),"}","\n")
		cat("\\hline\n","Size"," & ",paste(sep="",paste(colnames(tmp1X),collapse=" & "),"\\\\"),"\n")	
		for(k in 1:nrow(tmp1X)){ cat("\\hline\n",rownames(tmp1X[k,])," & ",paste(sep="",paste(tmp1X[k,],collapse=" & "),"\\\\"),"\n")		}
		cat("\\hline","\n")
		cat("\\end{tabular}","\n")
	}
 
 
 	
 	for( cType0 in c("C","S")){ # cType0="S";cType0="C"
 	
	for( cType2 in c("high","pass")){ # cType2="high"
		
		
		## B is the filtered column e.g. reduced number for only HIGH confidence variants
		
		if(cType0 == "C"){cSampleX="FR05812662"; fileStem="rS_rC"} 
   		if(cType0 == "S"){cSampleX=cSample; fileStem="rC_rS"}
		
  		if(cType0 == "C" && cType2 == "high" ){captionText=paste("Concordance of high confidence variants of control FR05812662", sep="")}
   		if(cType0 == "C" && cType2 == "pass" ){captionText=paste("Concordance of high confidence and pass variants of control FR05812662", sep="")}
   		if(cType0 == "S" && cType2 == "high" ){captionText=paste("Concordance of high confidence variants of test sample ", cSample,sep="")}
   		if(cType0 == "S" && cType2 == "pass" ){captionText=paste("Concordance of high confidence and pass variants of test sample ", cSample,sep="")}

		cat(paste("\\subsection{",captionText,"}\n",sep=""))   
		cat(paste("\\begin{figure}[ht]\n",sep=""))  
   		cat(paste("\\includegraphics[height=100pt]{figure/QC-Venn-sliced-",cType2,"-as-",cType0,".png}\n",sep=""))  
 		cat(paste("\\end{figure}\n",sep=""))  

		for( cType1 in c("CNV","SV")){ # cType1="CNV"  	
			
			cat(paste("\\textbf{",cType1,"}\n",sep=""))
			cat("\\begin{table}[H]","\n")
			cType=paste(sep="",cType2,cType1)
			concFileC=paste(sep="",contrStatsPathC,"/",cType,"_avg_",fileStem,".tab")
			expectedCAvg=read.table(concFileC, header=T, sep="\t", stringsAsFactors=FALSE)
			concFileC=paste(sep="",contrStatsPathC,"/",cType,"_sd_",fileStem,".tab")
			expectedCSd=read.table(concFileC, header=T, sep="\t", stringsAsFactors=FALSE)
		
			concFile=paste(sep="",projectPath,"/SVs/qc/reproducibility/",cSample,"/",cType,"_",fileStem,"/resulTable.tab")
			concRes=read.table(concFile, header=T, skip=2, sep="\t", stringsAsFactors=FALSE) ## take this countB, concB
			concResC=concRes[c(1:9,11),c(3,5,5)] 
			concResC[,3]=signif(concResC[,2]/concResC[,1]*100,3)
			rownames(concResC)=concRes[c(1:9,11),1]

			t2ContrXAvg=round(expectedCAvg[,"concB"][c(1:9,11)],1) 
			t2ContrXSd=round(expectedCSd[,"concB"][c(1:9,11)],1)
			t3ContrX=signif((concResC[,2]-t2ContrXAvg)/t2ContrXSd,2)
			
			t3ContrX[t2ContrXAvg==concResC[,1] & t2ContrXSd==0]=0 # if SD=0 but same number of concordant variant -> z score =0, to obtain a green OK
			concResC[,4]=paste(sep="",concResC[,2]," (",concResC[,3],"\\%)")
			concResC[,5]=paste(sep="","$\\mathit{\\mu}$ ",t2ContrXAvg,", $\\mathit{\\sigma}$ ",t2ContrXSd,", $\\mathit{z}$ ",t3ContrX)
		
			for(k in 1:nrow(concResC)){
				
				if(t3ContrX[k]<(-2) || is.na(t3ContrX[k]) || is.infinite(t3ContrX[k])){  concResC[k,5]=paste(sep="",concResC[k,5]," \\textcolor{orange}{!!!}")   }
				else{  concResC[k,5]=paste(sep="",concResC[k,5]," \\textcolor{green}{OK}") }
			}

			concResC=concResC[,c(1,4,5)]
			colnames(concResC)=c(paste(sep="",cSampleX," calls"),"Concordant calls","Expected")
		
			#cat("\\parbox{.49\\linewidth}{","\n")
			printTable2(concResC,paste(toupper(cType1),"",sep=""))	
			#cat("}","\n")
		
			cat("\\hfill","\n")
			cat("\\end{table}","\n")
		}
		
		
		cat(paste("\\clearpage\n",sep=""))  
  	
	
	}
	}
	
	} # end if



	cat(paste("\\clearpage\n",sep=""))  
  	cat(paste("\\section{Explanation QC and SV evaluation report}\n",sep=""))  
@
	
\subsection{General QC} 
Low quality input data may lead to unexpected results. To guarantee the quality of the results several variables that have an impact on or are an indicator for the quality of the results are measured and compiled in this automated QC report. 
QC metrics measured for a particular sample are compared to the expected range obtained from analyzing 500 germline controls samples. The control samples represent previously analyzed healthy individuals (MGRB cohort) that passed QC. The expected range is generally defined as two times the standard deviation ($\mathit{|z|}$ $\leq$ 2) from the mean of the control cohort, unless specified otherwise. If a measured metric is within expectations, it is marked with a green OK, else with three orange exclamation marks.  ClinSV is robust to a few metrics being outside the expected range, but within 4 times the standard deviation.\\[0.2in]
\textbf{Re 1. QC from bam alignment file}\\
Read pairs from Illumina paired end sequencing do not always align to the reference with their expected distance (roughly 450 bp, depending fragmentation size and size selection), regardless of the presence of structural variation. The sequencing process produces a small percentage of chimeric read pairs. These pairs originate from distant genomic locations. Despite these chimeric reads being randomly distributed; elevated numbers will impact the SV calling. Indicators for the relative abundance of chimeric pairs is the percentage of reads not mapping as proper pairs and the percentage of pairs mapping on different chromosomes. 
An uneven read coverage can affect CNVnator resulting in an elevated number of false CNV calls. The un-evenness of the read coverage is reflected by an increased standard deviation of the read coverage. 
The number of discordantly mapping pairs the prediction program Lumpy can handle is finite. The threshold for when the read mapping distance is considered discordant for pairs mapping with the expected read orientation is automatically determined (see online methods section), and results are shown here. The insert size distribution and resulting thresholds for concordant mapping distances have an impact on the smallest detectable deletions. 
To save computing time, metrics in this section are estimated for a 10 mega base pair region on chromosome 1 (chr1:20,000,001-30,000,000).\\[0.2in]
\textbf{Re 2. Input discordant pairs and split reads}\\
Number of discordant read pairs and split reads used as input for Lumpy. Deviating numbers could indicate library preparation or sequencing issues, deeper coverage, or samples with high numbers of structural variation, as expected for cancer samples.\\[0.2in]
\textbf{Re 3. Coverage by chromosome}\\
The average sequence coverage was determined for all chromosomes (see methods).
The number of sex chromosomes is inferred from the sequence coverage. Sex chromosome aneuploidy is visible here. 
This section also displays the chromosome wide coverage in intervals of 1 Mega bases. 
Grey dots below the black dots represent the average coverage in 500 control samples plus minus two times the standard deviation. The black dots indicate the coverage of the current sample. Truncated alignment files will not cover all grey dots.
One Mega base segments greater than five times the standard deviation of the control are colored blue, highlighting regions that have a copy number gain, and segments less than five times the standard deviation are colored in red, highlighting regions of copy number loss. The standard deviation is used, because regions close to the centromere tend to show a greater variation that is still considered normal, thus will not get highlighted in blue or red. Large deletions or duplications, that are likely clinical significant will be visible in this representation. N-regions usually correspond to centromeric or telomeric regions of the chromosome. The sex chromosomes will be compared to the expected coverage of X, XX, Y and/or Y0 (Y-zero), depending the average coverage of X and Y. Y0 (Y-Zero) indicates unspecific background read coverage of the Y chromosome and is helpful to reveal a partial presence of Y.\\[0.2in]
\textbf{Re 4. Number of called SVs}\\
Number of called variants by call confidence, SV type, caller, and number of variants affecting genes and being rare. Some metrics in this section show greater variation and are allowed 4 times the standard deviation from the control average. For instance the number of rare variants could be increased in an individual of a race underrepresented in the control cohort.\\[0.2in]

\subsection{NA12878 SV evaluation}
The following two sections are to evaluate the SV recall rate of a NA12878 sample and allow assessing the fitness of the entire SV detection pipeline. Metrics are compared to average values of nine NA12878 control samples. Here z values greater or equal to -2 are acceptable, in order to not penalize a greater concordance than expected from the nine NA12878 control samples. This section appears when option -eval is set.\\[0.2in]
\textbf{Re 5. Sensitivity}\\
This section shows the sensitivity of detecting gold standard deletion calls, as published by GIAB (Parikh et al. 2016), excluding 12 false positives $\mathit{>}$ 500 bases (Minoche et al. 2017).\\[0.2in]
\textbf{Re 6. Comparison to NA12878 sample}\\
Concordance of SV between NA12878 control sample (FR05812662) and current test sample, shown in percent of FR05812662 calls or in percent of test sample calls. High confidence calls generally have a higher reproducibility compared to all pass variants. CNVs and all SVs are tested separately.\\[0.2in]
  	

	
	



 
 
 
 \end{document}
 
 